"""
ç®€å•çš„ LangGraph æ™ºèƒ½ä½“åº”ç”¨
æ¼”ç¤ºä½¿ç”¨ LangGraph æž„å»ºåŸºç¡€æ™ºèƒ½ä½“å·¥ä½œæµ
"""

from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import operator
import os
import sys

# åŠ è½½çŽ¯å¢ƒå˜é‡
env_loaded = load_dotenv()

# æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
if env_loaded:
    print("âœ… æˆåŠŸè¯»å– .env æ–‡ä»¶")
else:
    print("âš ï¸  æœªæ‰¾åˆ° .env æ–‡ä»¶æˆ–æ–‡ä»¶ä¸ºç©º")
    print("æç¤ºï¼šè¯·å°† .env.example å¤åˆ¶ä¸º .env å¹¶é…ç½® API Key")

# åˆå§‹åŒ–å¤§æ¨¡åž‹
# ä¼˜å…ˆä½¿ç”¨æ™ºè°± AIï¼ˆå…è´¹ï¼‰ï¼Œå¦‚æžœæ²¡æœ‰é…ç½®åˆ™ä½¿ç”¨ OpenAI
zhipu_api_key = os.getenv("ZHIPU_API_KEY")
openai_api_key = os.getenv("OPENAI_API_KEY")

# æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ API Key é…ç½®çŠ¶æ€
print("\n" + "-" * 50)
print("API Key é…ç½®çŠ¶æ€ï¼š")
if zhipu_api_key:
    # åªæ˜¾ç¤ºéƒ¨åˆ† Keyï¼Œä¿æŠ¤éšç§
    masked_key = zhipu_api_key[:8] + "***" + zhipu_api_key[-4:] if len(zhipu_api_key) > 12 else "***"
    print(f"  ZHIPU_API_KEY: {masked_key}")
else:
    print("  ZHIPU_API_KEY: âŒ æœªé…ç½®")

if openai_api_key:
    masked_key = openai_api_key[:8] + "***" + openai_api_key[-4:] if len(openai_api_key) > 12 else "***"
    print(f"  OPENAI_API_KEY: {masked_key}")
else:
    print("  OPENAI_API_KEY: âŒ æœªé…ç½®")
print("-" * 50)

llm = None
api_provider = None

if zhipu_api_key:
    # ä½¿ç”¨æ™ºè°± AIï¼ˆå…è´¹ï¼‰
    api_provider = "æ™ºè°± AI"
    print(f"\nðŸ“Œ é€‰æ‹©ä½¿ç”¨: {api_provider} (glm-4-flash)\n")
    llm = ChatOpenAI(
        model="glm-4-flash",
        temperature=0.7,
        api_key=zhipu_api_key,  # type: ignore
        base_url="https://open.bigmodel.cn/api/paas/v4/"
    )
elif openai_api_key:
    # ä½¿ç”¨ OpenAI
    api_provider = "OpenAI"
    print(f"\nðŸ“Œ é€‰æ‹©ä½¿ç”¨: {api_provider} (gpt-3.5-turbo)\n")
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.7,
        api_key=openai_api_key  # type: ignore
    )
else:
    print("\nâš ï¸  æœªæ£€æµ‹åˆ°ä»»ä½•å¯ç”¨çš„ API Key\n")
    api_provider = None


def test_llm_connection():
    """æµ‹è¯•å¤§æ¨¡åž‹è¿žæŽ¥æ˜¯å¦æ­£å¸¸"""
    if llm is None:
        print("\n" + "=" * 60)
        print("âŒ æœªé…ç½® API Key")
        print("=" * 60)
        print("\nè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š")
        print("\nã€æŽ¨èã€‘æ™ºè°± AIï¼ˆå…è´¹ï¼‰ï¼š")
        print("  1. è®¿é—®ï¼šhttps://open.bigmodel.cn/")
        print("  2. æ³¨å†Œå¹¶ç™»å½•")
        print("  3. èŽ·å– API Keyï¼šä¸ªäººä¸­å¿ƒ -> API Keys")
        print("  4. åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼šZHIPU_API_KEY=ä½ çš„Key")
        print("\nOpenAIï¼ˆä»˜è´¹ï¼Œå›½å†…è®¿é—®å›°éš¾ï¼‰ï¼š")
        print("  1. è®¿é—®ï¼šhttps://platform.openai.com/")
        print("  2. èŽ·å– API Key")
        print("  3. åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ï¼šOPENAI_API_KEY=ä½ çš„Key")
        print("\n" + "=" * 60)
        return False
    
    print(f"\næ­£åœ¨æµ‹è¯• {api_provider} è¿žæŽ¥...")
    
    try:
        # å‘é€ä¸€ä¸ªç®€å•çš„æµ‹è¯•è¯·æ±‚
        response = llm.invoke("ä½ å¥½")
        if response and response.content:
            print(f"âœ… {api_provider} è¿žæŽ¥æˆåŠŸï¼")
            print(f"æµ‹è¯•å“åº”ï¼š{str(response.content)[:50]}...\n")
            return True
        else:
            print(f"âš ï¸  {api_provider} å“åº”å¼‚å¸¸")
            return False
    except Exception as e:
        error_msg = str(e)
        print(f"\n" + "=" * 60)
        print(f"âŒ {api_provider} è¿žæŽ¥å¤±è´¥")
        print("=" * 60)
        
        if "Connection error" in error_msg or "è¿žæŽ¥" in error_msg:
            if api_provider == "OpenAI":
                print("\nåŽŸå› ï¼šOpenAI API åœ¨å›½å†…æ— æ³•ç›´æŽ¥è®¿é—®")
                print("\nè§£å†³æ–¹æ¡ˆï¼š")
                print("  1. ã€æŽ¨èã€‘åˆ‡æ¢åˆ°æ™ºè°± AIï¼ˆå…è´¹ä¸”å¿«é€Ÿï¼‰")
                print("     - è®¿é—®ï¼šhttps://open.bigmodel.cn/")
                print("     - èŽ·å– API Key åŽé…ç½®åˆ° .env æ–‡ä»¶")
                print("     - é…ç½®é¡¹ï¼šZHIPU_API_KEY=ä½ çš„Key")
                print("  2. ä½¿ç”¨ä»£ç†/VPN è®¿é—® OpenAI")
            else:
                print(f"\nç½‘ç»œè¿žæŽ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š")
                print("  1. ç½‘ç»œè¿žæŽ¥æ˜¯å¦æ­£å¸¸")
                print("  2. API Key æ˜¯å¦æ­£ç¡®")
                print("  3. æ˜¯å¦æœ‰é˜²ç«å¢™æ‹¦æˆª")
        elif "API key" in error_msg or "Incorrect" in error_msg or "Invalid" in error_msg:
            print(f"\nAPI Key é”™è¯¯ï¼Œè¯·æ£€æŸ¥ï¼š")
            print(f"  1. .env æ–‡ä»¶ä¸­çš„ API Key æ˜¯å¦æ­£ç¡®")
            print(f"  2. API Key æ˜¯å¦å·²è¿‡æœŸæˆ–è¢«åˆ é™¤")
            print(f"  3. é‡æ–°èŽ·å– API Key å¹¶æ›´æ–°é…ç½®")
        else:
            print(f"\né”™è¯¯è¯¦æƒ…ï¼š{error_msg}")
        
        print("\n" + "=" * 60)
        return False


# å®šä¹‰çŠ¶æ€ç»“æž„
class AgentState(TypedDict):
    messages: Annotated[list, operator.add]
    next_step: str
    result: str


# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def process_input(state: AgentState) -> AgentState:
    """å¤„ç†åˆå§‹è¾“å…¥"""
    print("æ­£åœ¨å¤„ç†è¾“å…¥...")
    messages = state.get("messages", [])
    
    if messages:
        last_message = messages[-1]
        print(f"æ”¶åˆ°æ¶ˆæ¯: {last_message}")
        
        # ç®€å•çš„å†³ç­–é€»è¾‘
        if "hello" in last_message.lower():
            state["next_step"] = "greet"
        elif "help" in last_message.lower():
            state["next_step"] = "provide_help"
        else:
            state["next_step"] = "general_response"
    
    return state


def greet_user(state: AgentState) -> AgentState:
    """å‘ç”¨æˆ·é—®å€™"""
    print("æ­£åœ¨é—®å€™ç”¨æˆ·...")
    state["result"] = "ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„ LangGraph æ™ºèƒ½ä½“ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"
    state["next_step"] = "end"
    return state


def provide_help(state: AgentState) -> AgentState:
    """æä¾›å¸®åŠ©ä¿¡æ¯"""
    print("æ­£åœ¨æä¾›å¸®åŠ©...")
    state["result"] = """
    æˆ‘æ˜¯ä¸€ä¸ªç®€å•çš„ LangGraph æ™ºèƒ½ä½“ã€‚ä»¥ä¸‹æ˜¯æˆ‘èƒ½åšçš„äº‹æƒ…ï¼š
    - å½“ä½ å‘æˆ‘é—®å€™æ—¶ï¼Œæˆ‘ä¼šæ‰“æ‹›å‘¼
    - å½“ä½ éœ€è¦å¸®åŠ©æ—¶ï¼Œæˆ‘ä¼šæä¾›å¸®åŠ©ä¿¡æ¯
    - å¯¹å…¶ä»–è¾“å…¥ï¼Œæˆ‘ä¼šç»™å‡ºä¸€èˆ¬æ€§å›žå¤
    
    è¯•ç€è¯´ï¼š'ä½ å¥½'ã€'å¸®åŠ©' æˆ–å…¶ä»–ä»»ä½•å†…å®¹ï¼
    """
    state["next_step"] = "end"
    return state


def general_response(state: AgentState) -> AgentState:
    """æä¾›ä¸€èˆ¬æ€§å›žå¤ï¼ˆä½¿ç”¨å¤§æ¨¡åž‹ï¼‰"""
    messages = state.get("messages", [])
    last_message = messages[-1] if messages else "æ— å†…å®¹"
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†å¤§æ¨¡åž‹
    if llm is None:
        state["result"] = f"æ”¶åˆ°æ¶ˆæ¯ï¼š'{last_message}'\n\nâš ï¸ æœªé…ç½® API Keyï¼Œæ— æ³•ä½¿ç”¨å¤§æ¨¡åž‹ã€‚\nè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® ZHIPU_API_KEY æˆ– OPENAI_API_KEY"
        state["next_step"] = "end"
        return state
    
    print("æ­£åœ¨ä½¿ç”¨å¤§æ¨¡åž‹ç”Ÿæˆå›žå¤...")
    
    try:
        # ä½¿ç”¨å¤§æ¨¡åž‹ç”Ÿæˆå›žå¤
        response = llm.invoke(f"è¯·ç”¨å‹å¥½ã€ç®€æ´çš„æ–¹å¼å›žç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{last_message}")
        result_content = str(response.content) if response.content else "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç”Ÿæˆå›žå¤ã€‚"
        state["result"] = result_content
    except Exception as e:
        # å¦‚æžœå¤§æ¨¡åž‹è°ƒç”¨å¤±è´¥ï¼Œè¿”å›žé”™è¯¯ä¿¡æ¯
        error_msg = str(e)
        if "Connection error" in error_msg or "è¿žæŽ¥" in error_msg:
            state["result"] = f"âŒ ç½‘ç»œè¿žæŽ¥å¤±è´¥\n\nå¯èƒ½çš„åŽŸå› ï¼š\n1. OpenAI API åœ¨å›½å†…æ— æ³•ç›´æŽ¥è®¿é—®ï¼Œå»ºè®®ä½¿ç”¨æ™ºè°± AIï¼ˆå…è´¹ï¼‰\n2. è¯·é…ç½® ZHIPU_API_KEY æ¥ä½¿ç”¨å…è´¹çš„å›½å†…å¤§æ¨¡åž‹\n\nè¯¦ç»†é”™è¯¯ï¼š{error_msg}"
        else:
            state["result"] = f"æŠ±æ­‰ï¼Œæˆ‘åœ¨å¤„ç†ä½ çš„æ¶ˆæ¯æ—¶é‡åˆ°äº†é—®é¢˜ï¼š{error_msg}\nè¯·æ£€æŸ¥ä½ çš„ API Key é…ç½®æ˜¯å¦æ­£ç¡®ã€‚"
    
    state["next_step"] = "end"
    return state


def route_next(state: AgentState) -> str:
    """å†³å®šä¸‹ä¸€ä¸ªè¦è®¿é—®çš„èŠ‚ç‚¹"""
    next_step = state.get("next_step", "end")
    
    if next_step == "greet":
        return "greet"
    elif next_step == "provide_help":
        return "help"
    elif next_step == "general_response":
        return "general"
    else:
        return "end"


# æž„å»ºå›¾
def create_agent_graph():
    """åˆ›å»ºå¹¶ç¼–è¯‘æ™ºèƒ½ä½“å›¾"""
    workflow = StateGraph(AgentState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("process", process_input)
    workflow.add_node("greet", greet_user)
    workflow.add_node("help", provide_help)
    workflow.add_node("general", general_response)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("process")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "process",
        route_next,
        {
            "greet": "greet",
            "help": "help",
            "general": "general",
            "end": END
        }
    )
    
    # æ·»åŠ åˆ°ç»“æŸèŠ‚ç‚¹çš„è¾¹
    workflow.add_edge("greet", END)
    workflow.add_edge("help", END)
    workflow.add_edge("general", END)
    
    # ç¼–è¯‘å›¾
    app = workflow.compile()
    return app


def run_demo():
    """ä½¿ç”¨é¢„å®šä¹‰è¾“å…¥è¿è¡Œæ¼”ç¤º"""
    print("=" * 50)
    print("ç®€å• LangGraph æ™ºèƒ½ä½“ - æ¼”ç¤ºæ¨¡å¼")
    print("=" * 50)
    
    # æµ‹è¯•è¿žæŽ¥
    if not test_llm_connection():
        print("\nâš ï¸  å¤§æ¨¡åž‹åŠŸèƒ½ä¸å¯ç”¨ï¼Œä»…æ¼”ç¤ºåŸºç¡€åŠŸèƒ½\n")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = create_agent_graph()
    
    # æµ‹è¯•ç¤ºä¾‹
    test_inputs = [
        "ä½ å¥½ï¼",
        "æˆ‘éœ€è¦å¸®åŠ©",
        "ä»Šå¤©å¤©æ°”æ€Žä¹ˆæ ·ï¼Ÿ"
    ]
    
    for user_input in test_inputs:
        print(f"\n{'=' * 50}")
        print(f"ç”¨æˆ·: {user_input}")
        print("-" * 50)
        
        # è¿è¡Œæ™ºèƒ½ä½“
        result = agent.invoke({
            "messages": [user_input],
            "next_step": "",
            "result": ""
        })
        
        print("-" * 50)
        print(f"æ™ºèƒ½ä½“: {result['result']}")
    
    print(f"\n{'=' * 50}")
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 50)


def run_interactive():
    """è¿è¡Œäº¤äº’æ¨¡å¼ï¼Œç”¨æˆ·å¯ä»¥è¾“å…¥æ¶ˆæ¯"""
    print("=" * 50)
    print("ç®€å• LangGraph æ™ºèƒ½ä½“ - äº¤äº’æ¨¡å¼")
    print("=" * 50)
    
    # æµ‹è¯•è¿žæŽ¥
    if not test_llm_connection():
        print("\nè¯·å…ˆé…ç½® API Key åŽå†ä½¿ç”¨äº¤äº’æ¨¡å¼")
        sys.exit(1)
    
    print("è¾“å…¥ 'quit'ã€'exit' æˆ– 'q' é€€å‡º\n")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = create_agent_graph()
    
    while True:
        # èŽ·å–ç”¨æˆ·è¾“å…¥
        user_input = input("ä½ : ").strip()
        
        # æ£€æŸ¥é€€å‡ºå‘½ä»¤
        if user_input.lower() in ['quit', 'exit', 'q', 'é€€å‡º', 'ç»“æŸ']:
            print("\nå†è§ï¼")
            break
        
        if not user_input:
            continue
        
        # è¿è¡Œæ™ºèƒ½ä½“
        print("-" * 50)
        result = agent.invoke({
            "messages": [user_input],
            "next_step": "",
            "result": ""
        })
        
        print(f"æ™ºèƒ½ä½“: {result['result']}")
        print()


def main():
    """è¿è¡Œæ™ºèƒ½ä½“çš„ä¸»å‡½æ•°"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] == '--interactive':
        run_interactive()
    else:
        run_demo()


if __name__ == "__main__":
    main()
