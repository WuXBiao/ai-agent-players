"""
AIè§’è‰²æ‰®æ¼” - å‘½ä»¤è¡Œç‰ˆæœ¬
"""

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from dotenv import load_dotenv
import os

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¢„è®¾è§’è‰²
ROLES = {
    "1": {
        "name": "ğŸ§™â€â™‚ï¸ æ™ºæ…§å¯¼å¸ˆ",
        "prompt": "ä½ æ˜¯ä¸€ä½æ™ºæ…§çš„å¯¼å¸ˆï¼Œå–„äºç”¨ç®€å•çš„ä¾‹å­è§£é‡Šå¤æ‚é—®é¢˜ã€‚è¯­æ°”æ¸©å’Œä¸”å¯Œæœ‰å¯å‘æ€§ã€‚",
        "greeting": "æ¬¢è¿ï¼æˆ‘æ˜¯ä½ çš„æ™ºæ…§å¯¼å¸ˆã€‚æœ‰ä»€ä¹ˆé—®é¢˜æƒ³è¦æ¢è®¨å—ï¼Ÿ"
    },
    "2": {
        "name": "ğŸ­ èå£«æ¯”äºš", 
        "prompt": "ä½ æ˜¯èå£«æ¯”äºšï¼Œç”¨å¯Œæœ‰è¯—æ„çš„è¯­è¨€è¡¨è¾¾ï¼Œå¯¹äººæ€§æœ‰æ·±åˆ»æ´å¯Ÿã€‚",
        "greeting": "ä½ å¥½å•Šï¼Œäº²çˆ±çš„æœ‹å‹ï¼èå£«æ¯”äºšåœ¨æ­¤ï¼Œæ„¿ä¸ºæ±åˆ†äº«è¯—æ­Œä¸æ™ºæ…§ã€‚"
    },
    "3": {
        "name": "ğŸ¤– æœªæ¥AI",
        "prompt": "ä½ æ˜¯æ¥è‡ª2050å¹´çš„AIï¼Œäº†è§£æœªæ¥ç§‘æŠ€å‘å±•ï¼Œç”¨æœªæ¥ä¸»ä¹‰è§†è§’çœ‹é—®é¢˜ã€‚",
        "greeting": "ä½ å¥½ï¼Œ2024å¹´çš„æœ‹å‹ï¼æˆ‘æ˜¯æ¥è‡ª2050å¹´çš„ARIAã€‚å¾ˆé«˜å…´ä¸ä½ äº¤æµï¼"
    },
    "4": {
        "name": "ğŸ§‘â€ğŸ³ ç±³å…¶æ—å¤§å¨",
        "prompt": "ä½ æ˜¯ç±³å…¶æ—ä¸‰æ˜Ÿå¤§å¨ï¼Œå¯¹ç¾é£Ÿå……æ»¡æ¿€æƒ…ï¼Œå–„äºåˆ†äº«çƒ¹é¥ªæŠ€å·§ã€‚",
        "greeting": "Bonjour! æˆ‘æ˜¯Chef Antoineï¼è®©æˆ‘ä»¬æ¢ç´¢ç¾é£Ÿçš„å¥‡å¦™ä¸–ç•Œå§ï¼"
    },
    "5": {
        "name": "ğŸ± å‚²å¨‡çŒ«å¨˜",
        "prompt": "ä½ æ˜¯å¯çˆ±çš„å‚²å¨‡çŒ«å¨˜å°å–µï¼Œè¯´è¯ç”¨'å–µ~'ä½œè¯­æ°”è¯ï¼Œå¤–å†·å†…çƒ­ã€‚",
        "greeting": "å“¼~å±…ç„¶è®©æœ¬å–µç­‰è¿™ä¹ˆä¹…ï¼ä¸ã€ä¸æ˜¯åœ¨ç­‰ä½ å“¦å–µ~"
    },
    "6": {
        "name": "ğŸ•µï¸ ç¦å°”æ‘©æ–¯",
        "prompt": "ä½ æ˜¯å¤æ´›å…‹Â·ç¦å°”æ‘©æ–¯ï¼Œé€»è¾‘æ¨ç†èƒ½åŠ›è¶…ç¾¤ï¼Œè§‚å¯ŸåŠ›æ•é”ã€‚",
        "greeting": "Good day! æˆ‘æ˜¯ç¦å°”æ‘©æ–¯ã€‚æœ‰ä»€ä¹ˆè°œå›¢éœ€è¦æˆ‘è§£å¼€å—ï¼Ÿ"
    },
    "7": {
        "name": "ğŸ’ª å¥èº«æ•™ç»ƒ",
        "prompt": "ä½ æ˜¯å……æ»¡æ´»åŠ›çš„å¥èº«æ•™ç»ƒMaxï¼Œä¸“ä¸šä¸”å¯Œæœ‰æ¿€åŠ±æ€§ã€‚",
        "greeting": "å˜¿ï¼æˆ‘æ˜¯Maxï¼Œä½ çš„ç§äººæ•™ç»ƒï¼å‡†å¤‡å¥½æŒ‘æˆ˜è‡ªå·±äº†å—ï¼ŸLet's go!"
    },
    "8": {
        "name": "ğŸ¨ è‰ºæœ¯è¯„è®ºå®¶",
        "prompt": "ä½ æ˜¯çŸ¥åè‰ºæœ¯è¯„è®ºå®¶ï¼Œå¯¹å„ç§è‰ºæœ¯å½¢å¼æœ‰æ·±åˆ»ç†è§£ï¼Œç”¨ä¼˜é›…è¯­è¨€è¡¨è¾¾ã€‚",
        "greeting": "æ‚¨å¥½ï¼å¾ˆé«˜å…´ä¸æ‚¨æ¢è®¨è‰ºæœ¯ã€‚è®©æˆ‘ä»¬æ¬£èµè¿™ç¾å¦™çš„ä¸–ç•Œå§ã€‚"
    }
}

def init_llm():
    """åˆå§‹åŒ–å¤§æ¨¡å‹"""
    siliconflow_key = os.getenv("SILICONFLOW_API_KEY")
    zhipu_key = os.getenv("ZHIPU_API_KEY")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if siliconflow_key:
        print("ä½¿ç”¨ç¡…åŸºæµåŠ¨æ¨¡å‹...")
        return ChatOpenAI(
            model="Qwen/Qwen2.5-7B-Instruct",
            temperature=0.9,
            api_key=siliconflow_key,  # type: ignore
            base_url="https://api.siliconflow.cn/v1"
        )
    elif zhipu_key:
        print("ä½¿ç”¨æ™ºè°±AIæ¨¡å‹...")
        return ChatOpenAI(
            model="glm-4-flash",
            temperature=0.9,
            api_key=zhipu_key,  # type: ignore
            base_url="https://open.bigmodel.cn/api/paas/v4/"
        )
    elif openai_key:
        print("ä½¿ç”¨OpenAIæ¨¡å‹...")
        return ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.9,
            api_key=openai_key  # type: ignore
        )
    else:
        return None

def main():
    print("\n" + "="*60)
    print("ğŸ­ AIè§’è‰²æ‰®æ¼”æ¸¸æˆ (å‘½ä»¤è¡Œç‰ˆ)")
    print("="*60)
    
    llm = init_llm()
    if not llm:
        print("\nâŒ æœªé…ç½®API Key!")
        print("è¯·åœ¨.envæ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹ä»»ä¸€Key:")
        print("  - SILICONFLOW_API_KEY")
        print("  - ZHIPU_API_KEY")
        print("  - OPENAI_API_KEY")
        return
    
    print("\nâœ… AIæ¨¡å‹å·²å°±ç»ª\n")
    
    # é€‰æ‹©è§’è‰²
    print("è¯·é€‰æ‹©ä¸€ä¸ªè§’è‰²:\n")
    for key, role in ROLES.items():
        print(f"  {key}. {role['name']}")
    
    choice = input("\nè¾“å…¥ç¼–å· (1-8): ").strip()
    
    if choice not in ROLES:
        print("æ— æ•ˆé€‰æ‹©ï¼")
        return
    
    role = ROLES[choice]
    print(f"\n{'='*60}")
    print(f"å·²é€‰æ‹©è§’è‰²: {role['name']}")
    print(f"{'='*60}")
    print(f"\n{role['greeting']}\n")
    
    # å¯¹è¯å¾ªç¯
    history = []
    
    while True:
        user_input = input("\nä½ : ").strip()
        
        if not user_input:
            continue
        
        if user_input.lower() in ['quit', 'exit', 'q', 'é€€å‡º', 'ç»“æŸ']:
            print(f"\nå†è§ï¼å¾ˆé«˜å…´ä¸ä½ äº¤æµï¼\n")
            break
        
        if user_input.lower() in ['reset', 'é‡ç½®']:
            history = []
            print(f"\nå¯¹è¯å·²é‡ç½®ã€‚\n{role['greeting']}\n")
            continue
        
        try:
            # æ„å»ºæ¶ˆæ¯
            messages = [SystemMessage(content=role['prompt'])]
            for h in history:
                messages.append(HumanMessage(content=h['user']))
                messages.append(AIMessage(content=h['ai']))
            messages.append(HumanMessage(content=user_input))
            
            # è·å–å“åº”
            print(f"\n{role['name']}: ", end="", flush=True)
            response = llm.invoke(messages)
            ai_response = response.content
            print(ai_response)
            
            # ä¿å­˜å†å²
            history.append({
                'user': user_input,
                'ai': ai_response
            })
            
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {str(e)}")
    
    print("="*60 + "\n")

if __name__ == "__main__":
    main()
